// Run time of each Sort Programs.

time ./sort1 random5000.txt - change sort number and file name to test each Sort Algorithms

sort1 - random5000.txt real    0m0.087s
user    0m0.026s
sys     0m0.026s - random10000.txt real    0m0.195s
user    0m0.143s
sys     0m0.028s

- random50000.txt
real    0m6.247s
user    0m5.233s
sys     0m0.148s

- reversed5000.txt
real    0m0.059s
user    0m0.043s
sys     0m0.016s

- reversed10000.txt
real    0m0.257s
user    0m0.170s
sys     0m0.046s

- reversed50000.txt
real    0m5.832s
user    0m4.479s
sys     0m0.135s

- sorted5000.txt
real    0m0.020s
user    0m0.005s
sys     0m0.013s

- sorted10000.txt
real    0m0.077s
user    0m0.003s
sys     0m0.036s

- sorted50000.txt
real    0m1.457s
user    0m0.032s
sys     0m0.127s


sort2 - random5000.txt real    0m0.024s
user    0m0.004s
sys     0m0.015s - random10000.txt
real    0m0.083s
user    0m0.000s
sys     0m0.043s - random50000.txt
real    0m1.519s
user    0m0.037s
sys     0m0.142s

- reversed5000.txt
real    0m0.031s
user    0m0.003s
sys     0m0.017s

- reversed10000.txt
real    0m0.047s
user    0m0.000s
sys     0m0.037s

- reversed50000.txt
real    0m1.428s
user    0m0.030s
sys     0m0.133s

- sorted5000.txt
real    0m0.027s
user    0m0.000s
sys     0m0.019s

- sorted10000.txt
real    0m0.052s
user    0m0.007s
sys     0m0.030s

- sorted50000.txt
real    0m1.076s
user    0m0.034s
sys     0m0.137s
sort3 - random5000.txt
real    0m0.036s
user    0m0.022s
sys     0m0.013s

random10000.txt
real    0m0.139s
user    0m0.073s
sys     0m0.035s

- random50000.txt
real    0m2.948s
user    0m1.829s
sys     0m0.124s

- reversed5000.txt
real    0m0.038s
user    0m0.019s
sys     0m0.018s

- reversed10000.txt
 real    0m0.158s
user    0m0.068s
sys     0m0.051s

- reversed50000.txt
real    0m3.043s
user    0m2.088s
sys     0m0.142s

- sorted5000.txt
real    0m0.035s
user    0m0.027s
sys     0m0.008s

- sorted10000.txt
real    0m0.123s
user    0m0.066s
sys     0m0.031s

- sorted50000.txt
real    0m3.326s
user    0m1.878s
sys     0m0.170s

sort3 - random5000.txt
real    0m0.036s
user    0m0.022s
sys     0m0.013s

random10000.txt
real    0m0.139s
user    0m0.073s
sys     0m0.035s

- random50000.txt
real    0m2.948s
user    0m1.829s
sys     0m0.124s

- reversed5000.txt
real    0m0.038s
user    0m0.019s
sys     0m0.018s

- reversed10000.txt
 real    0m0.158s
user    0m0.068s
sys     0m0.051s

- reversed50000.txt
real    0m3.043s
user    0m2.088s
sys     0m0.142s

- sorted5000.txt
real    0m0.035s
user    0m0.027s
sys     0m0.008s

- sorted10000.txt
real    0m0.123s
user    0m0.066s
sys     0m0.031s

- sorted50000.txt
real    0m3.326s
user    0m1.878s
sys     0m0.170s



Notes to Remember:

// Bubble Sort - In the worst case you have to iterate across all the n elements n times.
So the worst case is n squared.
>> If the array is perfectly sorted though, you only
have to look at each of the elements once.
And if the swap counter is still 0, you can say this array is sorted.
And so in the best case, this is actually better than selection
sort-- it's omega of n.

// Selection Sort -
For sorted arrays - we actually have to still step through every single element of the array
in order to confirm that it is, in fact, the smallest element.
So the worst case runtime, we have to repeat a process n times,
once for each of n elements.
And in the best case scenario, we have to do the same.
So thinking back to our computational complexity toolbox,
what do you think is the worst case runtime for selection sort?
What do you think is the best case runtime for selection sort?

// Merge Sort - So as long as I'm consistent, as long as I always choose, in this case,
the left side is smaller, that will be fine for merge sort's purposes.
So now I'm left with this single element, this five.
In the best case scenario, sort of like selection sort,
the array is already sorted, but we don't know this.
We don't know this until we split it and recombine it back with this algorithm.
There's no sort of shortcut here other than doing a search beforehand.
But that's going to add extra time as well.
So the result here is that we have n elements--
and we might have to combine them if we're doubling-- log n times.
Mathematically, that's how it works.
And so actually, unlike the other algorithms
we've covered, in the worst case scenario, the runtime of merge sort
is O of n log n, which in general is going to be less than or faster than n
squared.
In the best case scenario, because we still have to go through this process
again, it is still n log n.
So in the best case scenario, it can be slower than, say,
bubble sort, where the array happens to be perfectly sorted.
As you may recall the omega there is n, and not n log n.
But in the worst case or maybe even in an average case,
merge sort is actually going to be faster, at the expense of maybe taking
up more memory because we have to recombine and create
new segments in memory for our sub-arrays.
So merge sort is a really powerful tool to have in your toolbox
once you understand recursion, because it can make the speed of sorting
an array that much faster.